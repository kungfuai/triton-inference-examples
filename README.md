This repo holds examples of using [`Triton`](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tritonserver) for model inference.